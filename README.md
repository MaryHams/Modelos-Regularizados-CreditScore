EvaluaciÃ³n y ComparaciÃ³n de Modelos Regularizados para Scoring Crediticio
Curso: Machine Learning â€“ MÃ³dulo 11
Autora: Mary Huaiquin Fecha: Octubre 2025
InstituciÃ³n: Kibernum CapacitaciÃ³n â€“ Data Science & Machine Learning
Herramientas: Python 3, Scikit-learn, Pandas, Matplotlib, Seaborn, Google Colab

1. DescripciÃ³n general del proyecto
Este proyecto corresponde a la EvaluaciÃ³n Modular 11 del curso de Machine Learning, cuyo objetivo fue aplicar modelos de clasificaciÃ³n regularizados para predecir el riesgo crediticio de clientes a partir de sus caracterÃ­sticas personales y financieras.

Se desarrollaron dos modelos: RegresiÃ³n LogÃ­stica Lasso (L1) y RegresiÃ³n LogÃ­stica Ridge (L2), utilizando el dataset pÃºblico â€œcredit-gâ€ disponible en OpenML.

El propÃ³sito fue comparar el desempeÃ±o, la interpretabilidad y el impacto de la regularizaciÃ³n sobre las variables predictoras.

2. Objetivos especÃ­ficos
Entrenar modelos de clasificaciÃ³n con regularizaciÃ³n L1 (Lasso) y L2 (Ridge).
Analizar el efecto de la regularizaciÃ³n en la selecciÃ³n de variables.
Evaluar el desempeÃ±o mediante mÃ©tricas de clasificaciÃ³n y curva ROC.
Comparar la interpretabilidad de ambos modelos.
Reflexionar sobre la aplicabilidad del modelo en contextos financieros reales.
3. DescripciÃ³n del dataset
Fuente: OpenML â€“ Dataset â€œcredit-gâ€
Observaciones: 1000 registros
Clases: Riesgo â€œbuenoâ€ (0) y â€œmaloâ€ (1)
NÃºmero de variables: 20 (mixtas: categÃ³ricas y numÃ©ricas)

Principales variables analizadas:

checking_status: estado de cuenta corriente
credit_history: historial crediticio
savings_status: nivel de ahorros
purpose: motivo del crÃ©dito
foreign_worker: trabajador extranjero
El preprocesamiento incluyÃ³:

ImputaciÃ³n de valores faltantes
CodificaciÃ³n de variables categÃ³ricas con OneHotEncoder
Escalado de variables numÃ©ricas
DivisiÃ³n en conjuntos de entrenamiento (80%) y prueba (20%)
4. Modelos aplicados
Modelo	Tipo de RegularizaciÃ³n	CaracterÃ­sticas principales
Lasso (L1)	Penaliza la suma de los valores absolutos de los coeficientes.	Elimina variables irrelevantes, mejorando interpretabilidad.
Ridge (L2)	Penaliza la suma de los cuadrados de los coeficientes.	Reduce la varianza y mejora la estabilidad del modelo.
5. MÃ©tricas de evaluaciÃ³n
MÃ©trica	Lasso	Ridge
Accuracy	0.78	0.78
Precision (Clase 1)	0.67	0.67
Recall (Clase 1)	0.53	0.53
F1-Score (Clase 1)	0.59	0.59
AUC	0.8127	0.8055
ConclusiÃ³n tÃ©cnica: ambos modelos muestran un rendimiento similar, con una leve ventaja de Lasso en AUC y mayor interpretabilidad.

6. AnÃ¡lisis de resultados
Ambos modelos clasifican correctamente 32 de 60 clientes de riesgo.
La curva ROC muestra un buen desempeÃ±o, con Lasso ligeramente superior.
Lasso elimina variables irrelevantes, lo que simplifica la explicaciÃ³n del modelo.
Ridge mantiene todas las variables, favoreciendo estabilidad pero reduciendo interpretabilidad.
Variables mÃ¡s influyentes detectadas:

checking_status_no checking â†’ alto riesgo.
credit_history_critical/other â†’ historial crÃ­tico.
purpose_education â†’ crÃ©ditos menos seguros.
foreign_worker_yes â†’ riesgo adicional.
savings_status_>=1000 â†’ factor protector.
7. Visualizaciones sugeridas
El anÃ¡lisis se complementa con:

Curva ROC â†’ evaluaciÃ³n del desempeÃ±o del modelo.
Matriz de confusiÃ³n â†’ errores de clasificaciÃ³n.
Importancia de variables (coeficientes) â†’ para comparar Lasso vs Ridge.
8. ReflexiÃ³n personal y aprendizajes
Este proyecto permitiÃ³ comprender cÃ³mo la regularizaciÃ³n controla la complejidad del modelo, evitando sobreajuste y mejorando la interpretabilidad.
AprendÃ­ que Lasso es Ãºtil cuando se busca simplicidad y selecciÃ³n automÃ¡tica de variables, mientras que Ridge es mÃ¡s apropiado cuando se desea conservar toda la informaciÃ³n.

AdemÃ¡s, comprendÃ­ que en contextos financieros, la interpretabilidad es esencial para justificar decisiones automatizadas, por lo que un modelo mÃ¡s explicable puede ser preferible a uno con una pequeÃ±a mejora en rendimiento.

9. Archivos del repositorio
ğŸ“ Scoring_Crediticio_Lasso_Ridge/
â”‚
â”œâ”€â”€ EM5_MHZ.ipynb                       # Notebook principal (Google Colab)
â”œâ”€â”€ Informe__Scoring_Crediticio_MHZ.pdf   # Informe tÃ©cnico completo
â””â”€â”€ README_Credit_Scoring_MHZ.md        # DescripciÃ³n del proyecto (este archivo)
10. Conclusiones generales
Lasso y Ridge ofrecen resultados similares, pero difieren en interpretabilidad.
Lasso es preferible cuando se requiere transparencia y selecciÃ³n de variables.
Ridge es mÃ¡s estable en presencia de colinealidad.
La combinaciÃ³n de anÃ¡lisis tÃ©cnico y reflexiÃ³n Ã©tica es clave en proyectos de scoring crediticio.
11. Referencias
Dataset: OpenML â€œcredit-gâ€.
LibrerÃ­as: scikit-learn, pandas, numpy, matplotlib, seaborn.
Curso: Machine Learning â€“ Kibernum CapacitaciÃ³n, 2025.
12. Entorno y versiones utilizadas
Este proyecto fue desarrollado en Python 3.10 (Google Colab) con las siguientes versiones de librerÃ­as para asegurar la reproducibilidad:

numpy == 1.26.4
pandas == 2.2.2
scikit-learn == 1.4.2
matplotlib == 3.8.4
seaborn == 0.13.2
openml == 0.14.2
joblib == 1.4.2
