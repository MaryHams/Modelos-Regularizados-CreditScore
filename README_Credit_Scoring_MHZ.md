# Evaluaci√≥n y Comparaci√≥n de Modelos Regularizados para Scoring Crediticio

### Curso: Machine Learning ‚Äì M√≥dulo 11  
**Autora:** Mary Huaiquin 
**Fecha:** Octubre 2025  
**Instituci√≥n:** Kibernum Capacitaci√≥n ‚Äì Data Science & Machine Learning  
**Herramientas:** Python 3, Scikit-learn, Pandas, Matplotlib, Seaborn, Google Colab  

---

## 1. Descripci√≥n general del proyecto

Este proyecto corresponde a la Evaluaci√≥n Modular 11 del curso de Machine Learning, cuyo objetivo fue aplicar modelos de clasificaci√≥n regularizados para predecir el **riesgo crediticio** de clientes a partir de sus caracter√≠sticas personales y financieras.  

Se desarrollaron dos modelos: **Regresi√≥n Log√≠stica Lasso (L1)** y **Regresi√≥n Log√≠stica Ridge (L2)**, utilizando el dataset p√∫blico **‚Äúcredit-g‚Äù** disponible en **OpenML**.  

El prop√≥sito fue comparar el desempe√±o, la interpretabilidad y el impacto de la regularizaci√≥n sobre las variables predictoras.  

---

## 2. Objetivos espec√≠ficos

- Entrenar modelos de clasificaci√≥n con regularizaci√≥n L1 (Lasso) y L2 (Ridge).  
- Analizar el efecto de la regularizaci√≥n en la selecci√≥n de variables.  
- Evaluar el desempe√±o mediante m√©tricas de clasificaci√≥n y curva ROC.  
- Comparar la interpretabilidad de ambos modelos.  
- Reflexionar sobre la aplicabilidad del modelo en contextos financieros reales.  

---

## 3. Descripci√≥n del dataset

**Fuente:** OpenML ‚Äì Dataset ‚Äúcredit-g‚Äù  
**Observaciones:** 1000 registros  
**Clases:** Riesgo ‚Äúbueno‚Äù (0) y ‚Äúmalo‚Äù (1)  
**N√∫mero de variables:** 20 (mixtas: categ√≥ricas y num√©ricas)  

Principales variables analizadas:
- `checking_status`: estado de cuenta corriente  
- `credit_history`: historial crediticio  
- `savings_status`: nivel de ahorros  
- `purpose`: motivo del cr√©dito  
- `foreign_worker`: trabajador extranjero  

El preprocesamiento incluy√≥:
- Imputaci√≥n de valores faltantes  
- Codificaci√≥n de variables categ√≥ricas con OneHotEncoder  
- Escalado de variables num√©ricas  
- Divisi√≥n en conjuntos de entrenamiento (80%) y prueba (20%)  

---

## 4. Modelos aplicados

| Modelo | Tipo de Regularizaci√≥n | Caracter√≠sticas principales |
|--------|------------------------|-----------------------------|
| **Lasso (L1)** | Penaliza la suma de los valores absolutos de los coeficientes. | Elimina variables irrelevantes, mejorando interpretabilidad. |
| **Ridge (L2)** | Penaliza la suma de los cuadrados de los coeficientes. | Reduce la varianza y mejora la estabilidad del modelo. |

---

## 5. M√©tricas de evaluaci√≥n

| M√©trica | Lasso | Ridge |
|----------|--------|--------|
| Accuracy | 0.78 | 0.78 |
| Precision (Clase 1) | 0.67 | 0.67 |
| Recall (Clase 1) | 0.53 | 0.53 |
| F1-Score (Clase 1) | 0.59 | 0.59 |
| AUC | **0.8127** | 0.8055 |

Conclusi√≥n t√©cnica: ambos modelos muestran un rendimiento similar, con una leve ventaja de **Lasso en AUC** y mayor interpretabilidad.

---

## 6. An√°lisis de resultados

- Ambos modelos clasifican correctamente 32 de 60 clientes de riesgo.  
- La curva ROC muestra un buen desempe√±o, con Lasso ligeramente superior.  
- **Lasso** elimina variables irrelevantes, lo que simplifica la explicaci√≥n del modelo.  
- **Ridge** mantiene todas las variables, favoreciendo estabilidad pero reduciendo interpretabilidad.  

Variables m√°s influyentes detectadas:
- `checking_status_no checking` ‚Üí alto riesgo.  
- `credit_history_critical/other` ‚Üí historial cr√≠tico.  
- `purpose_education` ‚Üí cr√©ditos menos seguros.  
- `foreign_worker_yes` ‚Üí riesgo adicional.  
- `savings_status_>=1000` ‚Üí factor protector.  

---

## 7. Visualizaciones sugeridas

El an√°lisis se complementa con:
- **Curva ROC** ‚Üí evaluaci√≥n del desempe√±o del modelo.  
- **Matriz de confusi√≥n** ‚Üí errores de clasificaci√≥n.  
- **Importancia de variables (coeficientes)** ‚Üí para comparar Lasso vs Ridge.  

---

## 8. Reflexi√≥n personal y aprendizajes

Este proyecto permiti√≥ comprender c√≥mo la **regularizaci√≥n controla la complejidad del modelo**, evitando sobreajuste y mejorando la interpretabilidad.  
Aprend√≠ que **Lasso** es √∫til cuando se busca simplicidad y selecci√≥n autom√°tica de variables, mientras que **Ridge** es m√°s apropiado cuando se desea conservar toda la informaci√≥n.  

Adem√°s, comprend√≠ que en contextos financieros, la interpretabilidad es esencial para justificar decisiones automatizadas, por lo que un modelo m√°s explicable puede ser preferible a uno con una peque√±a mejora en rendimiento.

---

## 9. Archivos del repositorio

```
üìÅ Scoring_Crediticio_Lasso_Ridge/
‚îÇ
‚îú‚îÄ‚îÄ EM5_MHZ.ipynb                       # Notebook principal (Google Colab)
‚îú‚îÄ‚îÄ Informe__Scoring_Crediticio_MHZ.pdf   # Informe t√©cnico completo
‚îî‚îÄ‚îÄ README_Credit_Scoring_MHZ.md        # Descripci√≥n del proyecto (este archivo)
```

---

## 10. Conclusiones generales

- Lasso y Ridge ofrecen resultados similares, pero difieren en interpretabilidad.  
- Lasso es preferible cuando se requiere transparencia y selecci√≥n de variables.  
- Ridge es m√°s estable en presencia de colinealidad.  
- La combinaci√≥n de an√°lisis t√©cnico y reflexi√≥n √©tica es clave en proyectos de scoring crediticio.

---

## 11. Referencias

- Dataset: OpenML ‚Äúcredit-g‚Äù.  
- Librer√≠as: scikit-learn, pandas, numpy, matplotlib, seaborn.  
- Curso: Machine Learning ‚Äì Kibernum Capacitaci√≥n, 2025.
  
## 12. Entorno y versiones utilizadas

Este proyecto fue desarrollado en **Python 3.10** (Google Colab) con las siguientes versiones de librer√≠as para asegurar la reproducibilidad:

- numpy == 1.26.4  
- pandas == 2.2.2  
- scikit-learn == 1.4.2  
- matplotlib == 3.8.4  
- seaborn == 0.13.2  
- openml == 0.14.2  
- joblib == 1.4.2  
